{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-02: Compare LLMs using Ragas Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "The LLM used in the Retrieval Augmented Generation (RAG) system has a major impact in the quality of the generated output. Evaluating the results generated by different LLMs can give an idea about the right llm to use for a particular use case.\n",
    "In this notebook, we will dive deep into building Q&A applications using the Retrieve API provide by Knowledge Bases for Amazon Bedrock, along with LangChain and Ragas for evaluating the responses. Here, we will query the knowledge base to get the desired number of document chunks based on similarity search, prompt the query using Anthropic Claude models and Meta Llama models, and then evaluate the responses effectively using evaluation metrics, such as faithfulness, answer_relevancy, context_recall, context_precision, context_entity_recall, answer_similarity, answer_correctness, harmfulness, maliciousness, coherence, correctness and conciseness.\n",
    "\n",
    "#### Notebook Walkthrough\n",
    "\n",
    "For our notebook we will use the `Retrieve API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. \n",
    "\n",
    "\n",
    "We will then use the text chunks being generated and augment it with the original prompt and pass it through the `anthropic.claude-3-sonnet-20240229-v1:0` model, the `anthropic.claude-3-haiku-20240307-v1:0` model, and the `amazon.titan-text-express-v1` model.\n",
    "\n",
    "Finally we will evaluate the generated responses using RAGAS on using metrics such as faithfulness, answer relevancy, and context precision. For evaluation, we will use `anthropic.claude-3-sonnet-20240229-v1:0`.\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "In this example, you will use Octank's financial 10k reports (sythetically generated dataset) as a text corpus to perform Q&A on. This data will be ingested into the knowledge base.\n",
    "\n",
    "### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration leveraging knowledge base created from LAB01\n",
    "We'll use the following data:\n",
    "\n",
    "* example financial statement documents of fake company \"Octank\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"sagemaker.config\").setLevel(logging.WARNING)\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "# Specify your bucket to be the default sagemaker bucket\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() #sagemaker-abcdef\n",
    "filename = 'octank_financial_10K.pdf'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Upload the file\n",
    "s3.upload_file(filename, bucket, filename)\n",
    "print(\"Upload Successful!!\\n\")\n",
    "print(f\"{filename} was successfully uploaded to {bucket}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the steps below to set up necessary packages\n",
    "\n",
    "1. Import the necessary libraries for creating `bedrock-runtime` for invoking foundation models and `bedrock-agent-runtime` client for using Retrieve API provided by Knowledge Bases for Amazon Bedrock. \n",
    "2. Import Langchain for: \n",
    "   1. Initializing bedrock model  `anthropic.claude-3-haiku-20240307-v1:0`, `anthropic.claude-3-sonnet-20240229-v1:0`, and `amazon.titan-text-express-v1` as our large language models to perform query completions using the RAG pattern. \n",
    "   2. Initializing bedrock model  `anthropic.claude-3-sonnet-20240229-v1:0` as our large language model to perform RAG assessment. \n",
    "   3. Initialize Langchain retriever integrated with knowledge bases. \n",
    "   4. Later in the notebook we will wrap the LLM and retriever with `RetrieverQAChain` for building our Q&A application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_runtime_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config\n",
    "                              )\n",
    "\n",
    "kwargs = {\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "llm_for_text_generation_haiku = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\", client=bedrock_runtime_client, model_kwargs=kwargs)\n",
    "\n",
    "llm_for_text_generation_sonnet = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", client=bedrock_runtime_client, model_kwargs=kwargs)\n",
    "\n",
    "llm_for_text_generation_amazon_titan = ChatBedrock(model_id=\"amazon.titan-text-express-v1\", client=bedrock_runtime_client, model_kwargs=kwargs)\n",
    "\n",
    "llm_for_evaluation = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", client=bedrock_runtime_client, model_kwargs=kwargs)\n",
    "\n",
    "llms = [llm_for_text_generation_haiku, llm_for_text_generation_sonnet,llm_for_text_generation_amazon_titan]\n",
    "print (\"List of LLMs to be evaluated with Ragas\")\n",
    "for llm in llms:\n",
    "    print (llm.model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Knowledge Base from Previous Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import interactive_sleep, create_knowledge_base, create_ds\n",
    "\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "\n",
    "cohere_embed_knowledge_base = create_knowledge_base(\n",
    "    index_name=\"cohere-embed-english-v3\", \n",
    "    collection_name=\"cohere-embed-english-v3\",\n",
    "    knowledge_base_name=\"cohere-embed-english-v3\",\n",
    "    vector_store_name=\"cohere-embed-english-v3\",\n",
    "    access_policy_name=\"cohere-embed-access-policy\",\n",
    "    embedding_model_arn=f\"arn:aws:bedrock:{region_name}::foundation-model/cohere.embed-english-v3\"\n",
    "    )\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"cohere.embed-english-v3\",client=bedrock_runtime_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve API: Process flow \n",
    "\n",
    "Create a `AmazonKnowledgeBasesRetriever` object from LangChain which will call the `Retrieve API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom\n",
    "workﬂows on top of the semantic search results. The output of the `Retrieve API` includes the the `retrieved text chunks`, the `location type` and `URI` of the source data, as well as the relevance `scores` of the retrievals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create retriever with the knowledge base ID\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=cohere_embed_knowledge_base[\"knowledgeBaseId\"],\n",
    "        retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 5}},\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=\"us-east-1\",\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Evaluation Data\n",
    "\n",
    "As RAGAS aims to be a reference-free evaluation framework, the required preparations of the evaluation dataset are minimal. You will need to prepare `question` and `ground_truths` pairs from which you can prepare the remaining information through inference as shown below. If you are not interested in the `context_recall` metric, you don’t need to provide the `ground_truths` information. In this case, all you need to prepare are the `questions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "questions = [\n",
    "    \"What was the primary reason for the increase in net cash provided by operating activities for Octank Financial in 2021?\",\n",
    "    \"In which year did Octank Financial have the highest net cash used in investing activities, and what was the primary reason for this?\",\n",
    "    \"What was the primary source of cash inflows from financing activities for Octank Financial in 2021?\",\n",
    "    \"Calculate the year-over-year percentage change in cash and cash equivalents for Octank Financial from 2020 to 2021.\",\n",
    "    \"Based on the information provided, what can you infer about Octank Financial's overall financial health and growth prospects?\"\n",
    "]\n",
    "ground_truth = [\n",
    "    \"The increase in net cash provided by operating activities was primarily due to an increase in net income and favorable changes in operating assets and liabilities.\",\n",
    "    \"Octank Financial had the highest net cash used in investing activities in 2021, at $360 million, compared to $290 million in 2020 and $240 million in 2019. The primary reason for this was an increase in purchases of property, plant, and equipment and marketable securities.\",\n",
    "    \"The primary source of cash inflows from financing activities for Octank Financial in 2021 was an increase in proceeds from the issuance of common stock and long-term debt.\",\n",
    "    \"To calculate the year-over-year percentage change in cash and cash equivalents from 2020 to 2021: \\\n",
    "    2020 cash and cash equivalents: $350 million \\\n",
    "    2021 cash and cash equivalents: $480 million \\\n",
    "    Percentage change = (2021 value - 2020 value) / 2020 value * 100 \\\n",
    "    = ($480 million - $350 million) / $350 million * 100 \\\n",
    "    = 37.14% increase\",\n",
    "    \"Based on the information provided, Octank Financial appears to be in a healthy financial position and has good growth prospects. The company has consistently increased its net cash provided by operating activities, indicating strong profitability and efficient management of working capital. Additionally, Octank Financial has been investing in long-term assets, such as property, plant, and equipment, and marketable securities, which suggests plans for future growth and expansion. The company has also been able to finance its growth through the issuance of common stock and long-term debt, indicating confidence from investors and lenders. Overall, Octank Financial's steady increase in cash and cash equivalents over the past three years provides a strong foundation for future growth and investment opportunities.\"\n",
    "]\n",
    "\n",
    "def execute_rag(llm):\n",
    "    answers = []\n",
    "    contexts = []\n",
    "    kb_id = retriever.knowledge_base_id\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm, retriever=retriever, return_source_documents=True\n",
    "    )\n",
    "    print(f\"Answering questions for llm: {llm.model_id}...\")\n",
    "    for query in questions:\n",
    "        response = qa_chain.invoke(query)\n",
    "        answers.append(response[\"result\"])\n",
    "        contexts.append([docs.page_content for docs in response[\"source_documents\"]])\n",
    "    # To dict\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truth\": ground_truth\n",
    "    }\n",
    "    return llm.model_id, data\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(execute_rag, llm) for llm in llms]\n",
    "    datasets = {}\n",
    "    for future in futures:\n",
    "        model_id, data = future.result()\n",
    "        datasets[model_id] = Dataset.from_dict(data)\n",
    "\n",
    "print(\"Questions answered and datasets created!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the RAG application with different LLMs\n",
    "First, import all the metrics you want to use from `ragas.metrics`. Then, you can use the `evaluate()` function and simply pass in the relevant metrics and the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LLM Model RAGAS comparisson\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import (\n",
    "harmfulness, \n",
    "maliciousness, \n",
    "coherence, \n",
    "correctness, \n",
    "conciseness\n",
    ")\n",
    "\n",
    "#specify the metrics here\n",
    "metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        context_entity_recall,\n",
    "        answer_similarity,\n",
    "        answer_correctness,\n",
    "        harmfulness, \n",
    "        maliciousness, \n",
    "        coherence, \n",
    "        correctness, \n",
    "        conciseness\n",
    "    ]\n",
    "\n",
    "def evaluate_llm(llm, embeddings, datasets, llm_for_evaluation):\n",
    "    llm_model_id = llm.model_id\n",
    "    result = evaluate(\n",
    "        dataset=datasets[llm_model_id],\n",
    "        metrics=metrics,\n",
    "        llm=llm_for_evaluation,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "    return llm_model_id, result.to_pandas()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(evaluate_llm, llm, bedrock_embeddings, datasets, llm_for_evaluation) for i, llm in enumerate(llms)]\n",
    "    dfs = {}\n",
    "    for future in futures:\n",
    "        model_id, df = future.result()\n",
    "        dfs[model_id] = df\n",
    "\n",
    "print(\"Ragas evaluation complete!!\")\n",
    "# disregard any \"failed to parse output\" errors. Those originate from the Ragas library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS METRICS AND RESULTS ANALYSIS\n",
    "\n",
    "\n",
    "Just like in any machine learning system, the performance of individual components within the LLM and RAG pipeline has a significant impact on the overall experience. Ragas offers metrics tailored for evaluating each component of your RAG pipeline in isolation\n",
    "\n",
    "\n",
    "<!-- ![data_ingestion.png](./images/data_ingestion.png) -->\n",
    "<img src=\"./assets/RAGAS_Scores.png\" width=50% height=20% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall',\n",
    "                'context_entity_recall', 'answer_similarity', 'answer_correctness', 'harmfulness',\n",
    "                'maliciousness', 'coherence', 'correctness', 'conciseness']\n",
    "\n",
    "\n",
    "# Calculate the mean of numeric columns for each DataFrame\n",
    "means = []\n",
    "kb_names = []\n",
    "llm_names = []\n",
    "for key, df in dfs.items():\n",
    "    mean_values = df[numeric_cols].mean()\n",
    "    means.append(mean_values)\n",
    "  \n",
    "    llm_name = next((llm.model_id for i, llm in enumerate(llms) if llm.model_id == key), 'Unknown')\n",
    "    llm_names.append(llm_name)\n",
    "\n",
    "# Combine the means into a single DataFrame\n",
    "means_df = pd.DataFrame(means, columns=numeric_cols)\n",
    "means_df = means_df.set_index(pd.Series(llm_names))\n",
    "\n",
    "# Reshape the DataFrame for plotting\n",
    "means_df = means_df.reset_index().melt(id_vars='index', value_vars=numeric_cols, var_name='Metric', value_name='Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the means as a bar chart\n",
    "bar_plot = means_df[0:21].set_index(['Metric', 'index'])['Mean'].unstack().plot(kind='bar', ax=ax, figsize=(20, 6), width=0.8, legend=True)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "ax.set_title('Ragas Performance - Metrics Block1', fontsize=14)\n",
    "ax.set_xlabel('Metrics', fontsize=12)\n",
    "ax.set_ylabel('Average', fontsize=12)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Update the legend labels with KB names\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# ax.legend(handles, llm_names, loc='upper right', ncol=1)\n",
    "ax.legend(handles, llm_names, loc='lower right', ncol=1)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the means as a bar chart\n",
    "bar_plot = means_df[21:].set_index(['Metric', 'index'])['Mean'].unstack().plot(kind='bar', ax=ax, figsize=(20, 6), width=0.8, legend=True)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "ax.set_title('Ragas Performance - Metrics Block2', fontsize=14)\n",
    "ax.set_xlabel('Metrics', fontsize=12)\n",
    "ax.set_ylabel('Average', fontsize=12)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Update the legend labels with KB names\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# ax.legend(handles, llm_names, loc='upper right', ncol=1)\n",
    "ax.legend(handles, llm_names, loc='lower right', ncol=1)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (means_df[:18])\n",
    "\n",
    "print (means_df[18:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Please note the scores above gives a relative idea on the performance of your RAG application and should be used with caution and not as standalone scores. Also note, that we have used only 5 question/answer pairs for evaluation, as best practice, you should use enough data to cover different aspects of your document for evaluating model.\n",
    "\n",
    "Based on the scores, you can review other components of your RAG workflow to further optimize the scores, few recommended options are to review your chunking strategy, prompt instructions, adding more numberOfResults for additional context and so on. "
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
